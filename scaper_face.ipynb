{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c040731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuration charg√©e\n",
      " Dossier de sortie: facebook_data\n",
      " 1 profil(s) configur√©(s)\n",
      "\n",
      " CODE PR√äT ! Voici comment utiliser le scraper multi-profils :\n",
      "======================================================================\n",
      " D√©marrage du scraping de 1 profil(s)\n",
      " Driver initialis√© avec succ√®s\n",
      " Acc√®s √† la page de connexion Facebook\n",
      " Email saisi\n",
      " Mot de passe saisi\n",
      " Tentative de connexion...\n",
      " Connexion r√©ussie\n",
      " D√©but du scraping de uvburkina - Objectif: 10 posts\n",
      " Navigation vers le profil: https://www.facebook.com/uvburkina\n",
      " 1 posts extraits de cette page (uvburkina)\n",
      " 0 doublons supprim√©s\n",
      " Progression uvburkina: 1/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 1 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 3/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 2 doublons supprim√©s\n",
      " Progression uvburkina: 4/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 4 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 5/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 3 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 5/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 5 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 7/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 6 posts extraits de cette page (uvburkina)\n",
      " 5 doublons supprim√©s\n",
      " Progression uvburkina: 8/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 5 posts extraits de cette page (uvburkina)\n",
      " 5 doublons supprim√©s\n",
      " Progression uvburkina: 8/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 4 posts extraits de cette page (uvburkina)\n",
      " 4 doublons supprim√©s\n",
      " Progression uvburkina: 8/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 4 posts extraits de cette page (uvburkina)\n",
      " 4 doublons supprim√©s\n",
      " Progression uvburkina: 8/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 4 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 9/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 4 posts extraits de cette page (uvburkina)\n",
      " 4 doublons supprim√©s\n",
      " Progression uvburkina: 9/10 posts uniques collect√©s\n",
      " Scroll de 500px effectu√©\n",
      " 4 posts extraits de cette page (uvburkina)\n",
      " 3 doublons supprim√©s\n",
      " Progression uvburkina: 10/10 posts uniques collect√©s\n",
      " Scraping de uvburkina termin√©: 10 posts collect√©s\n",
      "\n",
      " R√âSUM√â DES POSTS COLLECT√âS\n",
      "==================================================\n",
      "Nombre total de posts: 10\n",
      "Nombre de profils scrap√©s: 1\n",
      "  - uvburkina: 10 posts\n",
      "\n",
      " APER√áU DES PREMIERS POSTS:\n",
      "==================================================\n",
      "\n",
      "Post 1 (uvburkina):\n",
      " Profil: https://www.facebook.com/uvburkina\n",
      " Titre: ùêîùêï-ùêÅùêÖ : ùêãùêöùêßùêúùêûùê¶ùêûùêßùê≠ ùêùùêû ùê•ùêö ùêùùêûùêÆùê±ùê¢ùêûÃÄùê¶ùêû ùê¨ùêûùê¨ùê¨ùê¢ùê®ùêß ùêù‚ÄôùêûÃÅùêØùêöùê•ùêÆùêöùê≠ùê¢ùê®ùêß ùêùùêûùê¨ ùê´ùêûùê¨ùê¨ùê®ùêÆùê´ùêúùêûùê¨ ùê©ùêûÃÅùêùùêöùê†ùê®ùê†ùê¢ùê™ùêÆùêûùê¨ ùê¢ùê¶ùê©ùê•ùêûÃÅùê¶ùêûùêßùê≠ùêûÃÅùêûùê¨ ...\n",
      " Commentaires: Universit√© Virtuelle du Burkina Faso - UVBFbonjour vous pouvez songer √† r√©pondre aux questions des g...\n",
      "------------------------------\n",
      "\n",
      "Post 2 (uvburkina):\n",
      " Profil: https://www.facebook.com/uvburkina\n",
      " Titre: ùêàùêßùêØùê¢ùê≠ùêöùê≠ùê¢ùê®ùêß ùêöùêÆùê± ùêßùê®ùêÆùêØùêûùêöùêÆùê± ùêõùêöùêúùê°ùêûùê•ùê¢ùêûùê´ùê¨Le Minist√®re de l‚ÄôEnseignement‚Ä¶En voir plus...\n",
      " Commentaires: Attendez s√©rieusementUniversit√© Virtuelle du Burkina Faso - UVBFheein , Nos Ordinateurs vont venir q...\n",
      "------------------------------\n",
      "\n",
      "Post 3 (uvburkina):\n",
      " Profil: https://www.facebook.com/uvburkina\n",
      " Titre: ùêëùêûùê≠ùê®ùêÆùê´ ùê¨ùêÆùê´ ùê•‚ÄôùêûÃÅùê¶ùê¢ùê¨ùê¨ùê¢ùê®ùêß ¬´ ùêÇùê°ùê®ùê¢ùê¨ùê¢ùê´ ùê¶ùê®ùêß ùêûÃÅùêúùê®ùê•ùêû ¬ªL‚ÄôUniversit√© Virtuelle du Burkin‚Ä¶En voir plus...\n",
      " Commentaires: F√©licitations √† tous le personnel....\n",
      "------------------------------\n",
      " Donn√©es sauvegard√©es dans: facebook_data/facebook_posts_comments_20250920_161655.csv\n",
      "\n",
      " Scraping termin√© avec succ√®s!\n",
      " Fichier sauvegard√©: facebook_data/facebook_posts_comments_20250920_161655.csv\n",
      " Driver ferm√© avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1 : Imports et Configuration\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Configuration globale\n",
    "EMAIL = \"bonituynathan@gmail.com\"  # √Ä changer pour la s√©curit√©\n",
    "PASSWORD = \"Probook650G1#\"  # √Ä changer pour la s√©curit√©\n",
    "\n",
    "# Liste des profils √† scraper - AJOUTEZ VOS URLS ICI\n",
    "PROFILE_URLS = [\n",
    "    \"https://www.facebook.com/uvburkina\",\n",
    "    # Ajoutez d'autres URLs ici :\n",
    "    # \"https://www.facebook.com/autre_profil\",\n",
    "    # \"https://www.facebook.com/encore_un_profil\",\n",
    "]\n",
    "\n",
    "DEFAULT_PROFILE_URL = \"https://www.facebook.com/uvburkina\"\n",
    "OUTPUT_FOLDER = \"facebook_data\"\n",
    "SCROLL_STEP = 500\n",
    "SCROLL_DELAY = 2\n",
    "\n",
    "# Cr√©er le dossier de sortie si n√©cessaire\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(\" Configuration charg√©e\")\n",
    "print(f\" Dossier de sortie: {OUTPUT_FOLDER}\")\n",
    "print(f\" {len(PROFILE_URLS)} profil(s) configur√©(s)\")\n",
    "\n",
    "# Cellule 2 : Fonctions d'initialisation du driver\n",
    "def initialize_driver():\n",
    "    \"\"\"Initialise le driver Chrome avec options anti-d√©tection\"\"\"\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "        \n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        \n",
    "        print(\" Driver initialis√© avec succ√®s\")\n",
    "        return driver\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur lors de l'initialisation du driver: {e}\")\n",
    "        return None\n",
    "\n",
    "def close_driver(driver):\n",
    "    \"\"\"Ferme le driver de mani√®re s√©curis√©e\"\"\"\n",
    "    if driver:\n",
    "        try:\n",
    "            driver.quit()\n",
    "            print(\" Driver ferm√© avec succ√®s\")\n",
    "        except Exception as e:\n",
    "            print(f\" Erreur lors de la fermeture du driver: {e}\")\n",
    "\n",
    "# Cellule 3 : Fonctions de simulation humaine\n",
    "def simulate_human_typing(element, text):\n",
    "    \"\"\"Simule une frappe humaine r√©aliste\"\"\"\n",
    "    for char in text:\n",
    "        element.send_keys(char)\n",
    "        time.sleep(random.uniform(0.1, 0.3))\n",
    "        if random.random() < 0.1:  # Pause al√©atoire 10% du temps\n",
    "            time.sleep(random.uniform(0.3, 0.7))\n",
    "\n",
    "def slow_scroll(driver, step=SCROLL_STEP):\n",
    "    \"\"\"Fait d√©filer la page lentement\"\"\"\n",
    "    driver.execute_script(f\"window.scrollBy(0, {step});\")\n",
    "    time.sleep(SCROLL_DELAY)\n",
    "    print(f\" Scroll de {step}px effectu√©\")\n",
    "\n",
    "# Cellule 4 : Fonctions de connexion\n",
    "def login_to_facebook(driver, email=EMAIL, password=PASSWORD):\n",
    "    \"\"\"Se connecte √† Facebook\"\"\"\n",
    "    try:\n",
    "        driver.get(\"https://www.facebook.com/login\")\n",
    "        print(\" Acc√®s √† la page de connexion Facebook\")\n",
    "        \n",
    "        # Attendre et saisir l'email\n",
    "        email_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"email\"))\n",
    "        )\n",
    "        simulate_human_typing(email_input, email)\n",
    "        print(\" Email saisi\")\n",
    "        \n",
    "        # Attendre et saisir le mot de passe\n",
    "        password_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"pass\"))\n",
    "        )\n",
    "        simulate_human_typing(password_input, password)\n",
    "        print(\" Mot de passe saisi\")\n",
    "        \n",
    "        # Cliquer sur le bouton de connexion\n",
    "        login_button = driver.find_element(By.XPATH, \"//button[@type='submit']\")\n",
    "        ActionChains(driver)\\\n",
    "            .move_to_element(login_button)\\\n",
    "            .pause(random.uniform(0.2, 0.4))\\\n",
    "            .click()\\\n",
    "            .perform()\n",
    "        \n",
    "        print(\" Tentative de connexion...\")\n",
    "        time.sleep(15)  # Attendre la connexion\n",
    "        print(\" Connexion r√©ussie\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur lors de la connexion: {e}\")\n",
    "        return False\n",
    "\n",
    "def navigate_to_profile(driver, profile_url):\n",
    "    \"\"\"Navigue vers un profil Facebook sp√©cifique\"\"\"\n",
    "    try:\n",
    "        driver.get(profile_url)\n",
    "        time.sleep(4)\n",
    "        print(f\" Navigation vers le profil: {profile_url}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur lors de la navigation: {e}\")\n",
    "        return False\n",
    "\n",
    "# Cellule 5 : Fonctions utilitaires pour les profils\n",
    "def extract_profile_name(profile_url):\n",
    "    \"\"\"Extrait le nom du profil depuis l'URL\"\"\"\n",
    "    try:\n",
    "        if '/profile.php?id=' in profile_url:\n",
    "            # Pour les profils avec ID num√©rique\n",
    "            profile_id = profile_url.split('id=')[1].split('&')[0]\n",
    "            return f\"profile_{profile_id}\"\n",
    "        else:\n",
    "            # Pour les profils avec nom personnalis√©\n",
    "            profile_name = profile_url.rstrip('/').split('/')[-1]\n",
    "            return profile_name.replace('.', '_')\n",
    "    except:\n",
    "        return f\"profile_{int(time.time())}\"  # Fallback avec timestamp\n",
    "\n",
    "def add_profile_urls(new_urls):\n",
    "    \"\"\"Ajoute de nouvelles URLs √† la liste globale\"\"\"\n",
    "    global PROFILE_URLS\n",
    "    \n",
    "    if isinstance(new_urls, str):\n",
    "        new_urls = [new_urls]\n",
    "    \n",
    "    for url in new_urls:\n",
    "        if url not in PROFILE_URLS:\n",
    "            PROFILE_URLS.append(url)\n",
    "            print(f\" URL ajout√©e: {url}\")\n",
    "        else:\n",
    "            print(f\" URL d√©j√† pr√©sente: {url}\")\n",
    "    \n",
    "    print(f\" Total URLs dans la liste: {len(PROFILE_URLS)}\")\n",
    "    return PROFILE_URLS\n",
    "\n",
    "def show_current_urls():\n",
    "    \"\"\"Affiche la liste actuelle des URLs\"\"\"\n",
    "    print(f\" URLs configur√©es ({len(PROFILE_URLS)}):\")\n",
    "    for i, url in enumerate(PROFILE_URLS, 1):\n",
    "        profile_name = extract_profile_name(url)\n",
    "        print(f\"  {i}. {profile_name} - {url}\")\n",
    "    return PROFILE_URLS\n",
    "\n",
    "def remove_url(url_or_index):\n",
    "    \"\"\"Supprime une URL par son adresse ou son index\"\"\"\n",
    "    global PROFILE_URLS\n",
    "    \n",
    "    try:\n",
    "        if isinstance(url_or_index, int):\n",
    "            # Suppression par index\n",
    "            if 0 <= url_or_index < len(PROFILE_URLS):\n",
    "                removed_url = PROFILE_URLS.pop(url_or_index)\n",
    "                print(f\" URL supprim√©e: {removed_url}\")\n",
    "            else:\n",
    "                print(f\" Index invalide: {url_or_index}\")\n",
    "        else:\n",
    "            # Suppression par URL\n",
    "            if url_or_index in PROFILE_URLS:\n",
    "                PROFILE_URLS.remove(url_or_index)\n",
    "                print(f\" URL supprim√©e: {url_or_index}\")\n",
    "            else:\n",
    "                print(f\" URL non trouv√©e: {url_or_index}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur lors de la suppression: {e}\")\n",
    "    \n",
    "    return PROFILE_URLS\n",
    "\n",
    "def clear_all_urls():\n",
    "    \"\"\"Vide la liste des URLs\"\"\"\n",
    "    global PROFILE_URLS\n",
    "    PROFILE_URLS.clear()\n",
    "    print(\" Liste des URLs vid√©e\")\n",
    "    return PROFILE_URLS\n",
    "\n",
    "# Cellule 6 : Fonctions d'extraction des donn√©es\n",
    "def extract_posts_from_page(driver, profile_url=None):\n",
    "    \"\"\"Extrait les donn√©es des posts de la page actuelle\"\"\"\n",
    "    try:\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "        posts_data = []\n",
    "        \n",
    "        # Extraire le nom du profil pour l'identifier\n",
    "        profile_name = extract_profile_name(profile_url) if profile_url else \"unknown_profile\"\n",
    "        \n",
    "        posts = soup.find_all(\"div\", {\"class\": \"x1n2onr6 x1ja2u2z\"})\n",
    "        \n",
    "        for post in posts:\n",
    "            try:\n",
    "                # Extraction du texte du post (titre)\n",
    "                message_elements = post.find_all(\"div\", {\"data-ad-preview\": \"message\"})\n",
    "                post_text = \" \".join([msg.get_text(strip=True) for msg in message_elements])\n",
    "                \n",
    "                # Extraction des commentaires\n",
    "                comments = []\n",
    "                comment_elements = post.find_all(\"div\", {\"class\": \"xdj266r x14z9mp xat24cr x1lziwak x1vvkbs\"})\n",
    "                for comment in comment_elements:\n",
    "                    comment_text = comment.get_text(strip=True)\n",
    "                    if comment_text and len(comment_text) > 20:  # Filtrer les textes trop courts\n",
    "                        comments.append(comment_text)\n",
    "                \n",
    "                if post_text:  # Seulement ajouter si il y a du contenu\n",
    "                    posts_data.append({\n",
    "                        \"profile_name\": profile_name,\n",
    "                        \"profile_url\": profile_url,\n",
    "                        \"post_text\": post_text,\n",
    "                        \"comments\": \" | \".join(comments),  # S√©parer les commentaires par des |\n",
    "                        \"extracted_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\" Erreur lors de l'extraction d'un post: {e}\")\n",
    "                continue\n",
    "                \n",
    "        print(f\" {len(posts_data)} posts extraits de cette page ({profile_name})\")\n",
    "        return posts_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur lors de l'extraction des posts: {e}\")\n",
    "        return []\n",
    "\n",
    "def remove_duplicates(data_list):\n",
    "    \"\"\"Supprime les posts en double\"\"\"\n",
    "    seen = set()\n",
    "    unique_data = []\n",
    "    for data in data_list:\n",
    "        # Utiliser le texte du post comme identifiant unique\n",
    "        identifier = data.get('post_text', '')\n",
    "        if identifier and identifier not in seen:\n",
    "            seen.add(identifier)\n",
    "            unique_data.append(data)\n",
    "    \n",
    "    print(f\" {len(data_list) - len(unique_data)} doublons supprim√©s\")\n",
    "    return unique_data\n",
    "\n",
    "# Cellule 7 : Fonctions de scraping\n",
    "def scrape_facebook_posts(driver, max_posts=10, profile_url=DEFAULT_PROFILE_URL):\n",
    "    \"\"\"Fonction principale de scraping des posts Facebook pour un profil\"\"\"\n",
    "    profile_name = extract_profile_name(profile_url)\n",
    "    print(f\" D√©but du scraping de {profile_name} - Objectif: {max_posts} posts\")\n",
    "    \n",
    "    # Navigation vers le profil\n",
    "    if not navigate_to_profile(driver, profile_url):\n",
    "        return []\n",
    "    \n",
    "    all_posts = []\n",
    "    scroll_attempts = 0\n",
    "    max_scroll_attempts = 50  # Limite de s√©curit√©\n",
    "    \n",
    "    while len(all_posts) < max_posts and scroll_attempts < max_scroll_attempts:\n",
    "        # Extraire les posts de la page actuelle\n",
    "        posts = extract_posts_from_page(driver, profile_url)\n",
    "        all_posts.extend(posts)\n",
    "        \n",
    "        # Supprimer les doublons\n",
    "        all_posts = remove_duplicates(all_posts)\n",
    "        \n",
    "        print(f\" Progression {profile_name}: {len(all_posts)}/{max_posts} posts uniques collect√©s\")\n",
    "        \n",
    "        # Si on a assez de posts, arr√™ter\n",
    "        if len(all_posts) >= max_posts:\n",
    "            break\n",
    "        \n",
    "        # Faire d√©filer pour charger plus de contenu\n",
    "        slow_scroll(driver)\n",
    "        scroll_attempts += 1\n",
    "        \n",
    "        # Attendre un peu pour que le nouveau contenu se charge\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "    \n",
    "    # Limiter au nombre demand√©\n",
    "    final_posts = all_posts[:max_posts]\n",
    "    print(f\" Scraping de {profile_name} termin√©: {len(final_posts)} posts collect√©s\")\n",
    "    \n",
    "    return final_posts\n",
    "\n",
    "def scrape_multiple_profiles(driver, profile_urls, max_posts_per_profile=10):\n",
    "    \"\"\"Scrape plusieurs profils Facebook\"\"\"\n",
    "    all_profiles_data = []\n",
    "    \n",
    "    print(f\" Scraping de {len(profile_urls)} profils avec {max_posts_per_profile} posts chacun\")\n",
    "    \n",
    "    for i, url in enumerate(profile_urls, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\" Scraping du profil {i}/{len(profile_urls)}: {url}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            posts_data = scrape_facebook_posts(driver, max_posts_per_profile, url)\n",
    "            \n",
    "            if posts_data:\n",
    "                all_profiles_data.extend(posts_data)\n",
    "                print(f\" Profil {i} termin√©: {len(posts_data)} posts collect√©s\")\n",
    "            else:\n",
    "                print(f\" Aucun post collect√© pour le profil {i}\")\n",
    "            \n",
    "            # Pause entre les profils pour √©viter la d√©tection\n",
    "            if i < len(profile_urls):  # Pas de pause apr√®s le dernier profil\n",
    "                wait_time = random.uniform(5, 10)\n",
    "                print(f\" Pause de {wait_time:.1f}s avant le prochain profil...\")\n",
    "                time.sleep(wait_time)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Erreur lors du scraping du profil {i} ({url}): {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n Scraping multi-profils termin√©!\")\n",
    "    print(f\" Total: {len(all_profiles_data)} posts collect√©s sur {len(profile_urls)} profils\")\n",
    "    \n",
    "    return all_profiles_data\n",
    "\n",
    "# Cellule 8 : Fonctions de sauvegarde\n",
    "def save_to_csv(posts_data, filename=None):\n",
    "    \"\"\"Sauvegarde les donn√©es dans un fichier CSV bien format√©\"\"\"\n",
    "    if not posts_data:\n",
    "        print(\" Aucune donn√©e √† sauvegarder\")\n",
    "        return None\n",
    "    \n",
    "    # G√©n√©rer un nom de fichier si non fourni\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"facebook_posts_comments_{timestamp}.csv\"\n",
    "    \n",
    "    filepath = os.path.join(OUTPUT_FOLDER, filename)\n",
    "    \n",
    "    try:\n",
    "        # D√©finir les colonnes dans l'ordre souhait√©\n",
    "        fieldnames = ['profile_name', 'profile_url', 'post_text', 'comments', 'extracted_at']\n",
    "        \n",
    "        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            # √âcrire l'en-t√™te\n",
    "            writer.writeheader()\n",
    "            \n",
    "            # √âcrire les donn√©es\n",
    "            for post in posts_data:\n",
    "                writer.writerow(post)\n",
    "        \n",
    "        print(f\" Donn√©es sauvegard√©es dans: {filepath}\")\n",
    "        return filepath\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur lors de la sauvegarde CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_posts_summary(posts_data):\n",
    "    \"\"\"Affiche un r√©sum√© des posts collect√©s\"\"\"\n",
    "    if not posts_data:\n",
    "        print(\" Aucune donn√©e √† afficher\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n R√âSUM√â DES POSTS COLLECT√âS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Nombre total de posts: {len(posts_data)}\")\n",
    "    \n",
    "    # Statistiques par profil\n",
    "    profiles_stats = {}\n",
    "    for post in posts_data:\n",
    "        profile_name = post.get('profile_name', 'unknown')\n",
    "        if profile_name not in profiles_stats:\n",
    "            profiles_stats[profile_name] = 0\n",
    "        profiles_stats[profile_name] += 1\n",
    "    \n",
    "    print(f\"Nombre de profils scrap√©s: {len(profiles_stats)}\")\n",
    "    for profile, count in profiles_stats.items():\n",
    "        print(f\"  - {profile}: {count} posts\")\n",
    "    \n",
    "    print(f\"\\n APER√áU DES PREMIERS POSTS:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for idx, post in enumerate(posts_data[:3], 1):\n",
    "        print(f\"\\nPost {idx} ({post.get('profile_name', 'unknown')}):\")\n",
    "        print(f\" Profil: {post.get('profile_url', 'N/A')}\")\n",
    "        print(f\" Titre: {post['post_text'][:100]}...\")\n",
    "        print(f\" Commentaires: {post['comments'][:100]}...\")\n",
    "        print(f\"{'-'*30}\")\n",
    "\n",
    "# Cellule 9 : Fonction d'ex√©cution compl√®te\n",
    "def run_complete_scraping(max_posts=10, profile_urls=None):\n",
    "    \"\"\"Ex√©cute le scraping complet avec sauvegarde pour un ou plusieurs profils\"\"\"\n",
    "    driver = None\n",
    "    \n",
    "    # Utiliser la liste par d√©faut si aucune URL fournie\n",
    "    if profile_urls is None:\n",
    "        profile_urls = PROFILE_URLS\n",
    "    \n",
    "    # Convertir en liste si une seule URL est fournie\n",
    "    if isinstance(profile_urls, str):\n",
    "        profile_urls = [profile_urls]\n",
    "    \n",
    "    print(f\" D√©marrage du scraping de {len(profile_urls)} profil(s)\")\n",
    "    \n",
    "    try:\n",
    "        # Initialiser le driver\n",
    "        driver = initialize_driver()\n",
    "        if not driver:\n",
    "            return None\n",
    "        \n",
    "        # Se connecter √† Facebook\n",
    "        if not login_to_facebook(driver):\n",
    "            return None\n",
    "        \n",
    "        # Scraper les posts\n",
    "        if len(profile_urls) == 1:\n",
    "            # Scraping d'un seul profil\n",
    "            posts_data = scrape_facebook_posts(driver, max_posts, profile_urls[0])\n",
    "        else:\n",
    "            # Scraping de plusieurs profils\n",
    "            posts_data = scrape_multiple_profiles(driver, profile_urls, max_posts)\n",
    "        \n",
    "        if not posts_data:\n",
    "            print(\" Aucun post n'a pu √™tre collect√©\")\n",
    "            return None\n",
    "        \n",
    "        # Afficher le r√©sum√©\n",
    "        display_posts_summary(posts_data)\n",
    "        \n",
    "        # Sauvegarder les donn√©es dans un seul fichier CSV\n",
    "        csv_file = save_to_csv(posts_data)\n",
    "        \n",
    "        print(f\"\\n Scraping termin√© avec succ√®s!\")\n",
    "        print(f\" Fichier sauvegard√©: {csv_file}\")\n",
    "        \n",
    "        return posts_data, csv_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur g√©n√©rale: {e}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        close_driver(driver)\n",
    "\n",
    "# Cellule 10 : Exemples d'utilisation\n",
    "print(\"\\n CODE PR√äT ! Voici comment utiliser le scraper multi-profils :\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ex√©cution\n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    run_complete_scraping()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
